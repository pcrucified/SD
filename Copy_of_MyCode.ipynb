{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pcrucified/SD/blob/main/Copy_of_MyCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Delete Automatic1111 Folder for redownload"
      ],
      "metadata": {
        "id": "TRdTu0Huhkyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "import shutil\n",
        "\n",
        "\n",
        "Redownload = True #@param {type:\"boolean\"}\n",
        "\n",
        "if Redownload :\n",
        "  if os.path.exists('/content/drive/MyDrive/sd/'):\n",
        "     location = \"/content/drive/MyDrive/\"\n",
        "     dir = \"sd\"\n",
        "     path = os.path.join(location, dir)\n",
        "     shutil.rmtree(path)\n",
        "  elif not os.path.isdir('/content/drive/MyDrive/sd/stable-diffusion-webui'):\n",
        "    print('Folder not found')\n",
        "    %cd /content/drive/MyDrive/\n",
        "\n",
        "\n",
        "time.sleep(3)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "u-AWZ0J7g1m6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Requerment"
      ],
      "metadata": {
        "id": "7NkU7N_pcArX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "import os\n",
        "from IPython.display import HTML\n",
        "from subprocess import getoutput\n",
        "import random\n",
        "import string\n",
        "import time\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "! apt update\n",
        "! apt upgrade -y\n",
        "! apt install zstd -y\n",
        "\n",
        "!nvidia-smi -L\n",
        "! nvcc -V\n",
        "! free -h\n",
        "\n",
        "time.sleep(6)\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "skIKAJ8JganC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the Torch repo (forked to work with CUDA 10).\n",
        "\n",
        "!git clone https://github.com/nagadomi/distro.git torch --recursive"
      ],
      "metadata": {
        "id": "n4Pay456VmHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Automatic1111"
      ],
      "metadata": {
        "id": "voRrFzBKzE-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " if os.path.isdir('/content/drive/MyDrive/sd/stable-diffusion-webui/'):\n",
        "  print('GDrive folder already exists, will use it')\n",
        "  %cd '/content/drive/MyDrive/sd/stable-diffusion-webui'\n",
        "else:\n",
        "  print('GDrive folder not found, creating')\n",
        "  os.mkdir('/content/drive/MyDrive/sd')\n",
        "  !cd '/content/drive/MyDrive/sd'\n",
        "  !git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui '/content/drive/MyDrive/sd/stable-diffusion-webui'\n",
        "  %cd /content/drive/MyDrive/sd/stable-diffusion-webui/\n",
        "  !mkdir -p cache/{huggingface,torch}\n",
        "  %cd /content/\n",
        "\n",
        "time.sleep(6)\n",
        "clear_output()\n"
      ],
      "metadata": {
        "id": "AbUOYe8OmdyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Update Automatic1111"
      ],
      "metadata": {
        "id": "UL3K0m4WzVsD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "update = True #@param {type:\"boolean\"}\n",
        "if update:\n",
        "  print('Will update')\n",
        "  !rm -rf '/content/drive/MyDrive/sd/stable-diffusion-webui/repositories/k-diffusion'\n",
        "  %cd '/content/drive/MyDrive/sd/stable-diffusion-webui'\n",
        "  !git pull"
      ],
      "metadata": {
        "id": "AMzqz8hIzjCf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d059462-dac0-4d19-db88-e8deb6bddca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Will update\n",
            "/content/drive/MyDrive/sd/stable-diffusion-webui\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing Requirements"
      ],
      "metadata": {
        "id": "rWK4ctYB9l8r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#@title # Install Model \n",
        "\n",
        "token = \"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\"  # @param {type:\"string\"}\n",
        "\n",
        "Version = \"DL5Full\" #@param [\"DeleteFile\", \"DL4Lite\", \"DL4Full\", \"DL5Lite\", \"DL5Full\"]\n",
        "\n",
        "\n",
        "\n",
        "def dltefile(token) :\n",
        "  if os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "    !rm /content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt\n",
        "  \n",
        "  else :\n",
        "    %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/\n",
        "\n",
        "\n",
        "\n",
        "def dl4l(token) :\n",
        "    if os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      print(\"Model already downloaded, moving to next step\")\n",
        "    else:\n",
        "      %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/\n",
        "      ! curl -LJ  https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4.ckpt -o model.ckpt {'-H \"Authorization: Bearer ' + token + '\"' if token else \"\"}\n",
        "\n",
        "\n",
        "\n",
        "def dl4f(token) :\n",
        "    if os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      print(\"Model already downloaded, moving to next step\")\n",
        "    else:\n",
        "      %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/\n",
        "      ! curl -LJ  https://huggingface.co/CompVis/stable-diffusion-v-1-4-original/resolve/main/sd-v1-4-full-ema.ckpt -o model.ckpt {'-H \"Authorization: Bearer ' + token + '\"' if token else \"\"}\n",
        "\n",
        "\n",
        "\n",
        "def dl5l(token) :\n",
        "    if os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      print(\"Model already downloaded, moving to next step\")\n",
        "    else:\n",
        "      %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/\n",
        "      ! curl -LJ  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt -o model.ckpt {'-H \"Authorization: Bearer ' + token + '\"' if token else \"\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dl5f(token) :\n",
        "    if os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/model.ckpt'):\n",
        "      print(\"Model already downloaded, moving to next step\")\n",
        "    else:\n",
        "      %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/Stable-diffusion/\n",
        "      ! curl -LJ  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.ckpt -o model.ckpt {'-H \"Authorization: Bearer ' + token + '\"' if token else \"\"}\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "if Version==\"DeleteFile\":\n",
        "  dltefile(token)\n",
        "\n",
        "if Version==\"DL4Lite\":\n",
        "  dl4l(token)\n",
        "\n",
        "if Version==\"DL4Full\":\n",
        "  dl4f(token)\n",
        "\n",
        "if Version==\"DL5Lite\":\n",
        "  dl5l(token)\n",
        "\n",
        "if Version==\"DL5Full\":\n",
        "  dl5f(token)"
      ],
      "metadata": {
        "id": "lG0Wuu_b9pkV",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GFGAN + ESRGAN + LDSR models"
      ],
      "metadata": {
        "id": "TRLeQX8J8zNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GFGAN + ESRGAN + LDSR ModelDownload\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "LDSR = True #@param {type:\"boolean\"}\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/gfpgan/GFPGANv1.3.pth'):\n",
        "  !mkdir /content/drive/MyDrive/sd/stable-diffusion-webui/models/gfpgan\n",
        "  %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/gfpgan\n",
        "  !wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n",
        "  clear_output()\n",
        "\n",
        "if not os.path.exists('/content/drive/MyDrive/sd/stable-diffusion-webui/models/realesrgan/RealESRGAN_x4plus.pth'):\n",
        "  !mkdir /content/drive/MyDrive/sd/stable-diffusion-webui/models/realesrgan/\n",
        "  %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/realesrgan/\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
        "  !wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
        "  clear_output()\n",
        "\n",
        "\n",
        "if LDSR:\n",
        "  if not os.path.exists('/stable-diffusion-webui/sd/models/ldsr/model.ckpt'):\n",
        "    !mkdir /content/drive/MyDrive/sd/stable-diffusion-webui/models/ldsr\n",
        "    %cd /content/drive/MyDrive/sd/stable-diffusion-webui/models/ldsr\n",
        "    !wget -O project.yaml https://heibox.uni-heidelberg.de/f/31a76b13ea27482981b4/?dl=1\n",
        "    clear_output()\n",
        "    !wget -O model.ckpt https://heibox.uni-heidelberg.de/f/578df07c8fc04ffbadf3/?dl=1\n",
        "    clear_output()"
      ],
      "metadata": {
        "id": "McKDWY_S-eDx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Installing xformers\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('it seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl  \n",
        "\n",
        "clear_output()\n",
        "print('DONE !')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "cellView": "form",
        "id": "ML4nrmeGEwMN",
        "outputId": "49d476e6-cb6f-4005-fac2-03c33cb9bfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it seems that your GPU is not supported at the moment\n",
            "it seems that your GPU is not supported at the moment\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-77114a939c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'it seems that your GPU is not supported at the moment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'T4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Ngrok \n",
        "\n",
        "use_ngrok = False  # @param {type: \"boolean\"}\n",
        "ngrok_auth_token = \"\"  # @param {type: \"string\"}\n",
        "ngrok_region = \"us\"  # @param [\"us\", \"eu\", \"au\", \"ap\", \"sa\", \"jp\", \"in\"]\n",
        "\n",
        "if not use_ngrok:\n",
        "    vars += \" --share\"\n",
        "else:\n",
        "    vars += f\" --ngrok {ngrok_auth_token} --ngrok-region {ngrok_region}\"\n"
      ],
      "metadata": {
        "id": "zYrq1lU6F3oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # Auth\n",
        "use_gradio_auth = False # @param {type:\"boolean\"}\n",
        "gradio_auth_username = \"username\" # @param {type:\"string\"}\n",
        "gradio_auth_password = \"password\" # @param {type:\"string\"}\n",
        "\n",
        "if use_gradio_auth:\n",
        "    vars += f\" --gradio-auth {gradio_auth_username}:{gradio_auth_password}\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "_mnS-pIKF7E4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CreateFiles"
      ],
      "metadata": {
        "id": "2mOSbGVOHed6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config_path = \"/content/drive/MyDrive/sd/stable-diffusion-webui/config\"\n",
        "output_path = \"/content/drive/MyDrive/sd/stable-diffusion-webui/output\"\n",
        "models_path = \"/content/drive/MyDrive/sd/stable-diffusion-webui/models\"\n",
        "\n",
        "\n",
        "gdrive_env_directory = \"/content/drive/MyDrive/sd/stable-diffusion-webui/conda-env\"\n",
        "gdrive_env_file = f\"{gdrive_env_directory}/env.tar.zst\"\n",
        "\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "os.makedirs(config_path, exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/embeddings\", exist_ok=True)\n",
        "os.makedirs(f\"{models_path}/hypernetworks\", exist_ok=True)\n",
        "\n",
        "! rm -Rf stable-diffusion-webui/embeddings && ln -s {models_path}/embeddings stable-diffusion-webui/embeddings\n",
        "! rm -Rf stable-diffusion-webui/models/hypernetworks && ln -s {models_path}/hypernetworks stable-diffusion-webui/models/hypernetworks"
      ],
      "metadata": {
        "id": "Q6TIGdS1GupH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_options = {k for (k, v) in run_string_with_variables.items() if v == \"True\"}\n",
        "vars = \" \".join(advanced_options)\n",
        "--ui-config-file {config_path}/ui-config.json \\\n",
        "--ui-settings-file {config_path}/config.json \\\n",
        "--styles-file {config_path}/styles.csv \\\n",
        "{vars} \\\n",
        "{custom_arguments}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "mtpw3FH-RJ35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFWtw-6EPrKi"
      },
      "outputs": [],
      "source": [
        "#install miniconda \n",
        "#from https://stackoverflow.com/questions/62417114/how-do-i-install-anaconda-in-google-colab\n",
        "\n",
        "if not os.path.exists(\"/usr/local/bin/conda\"):\n",
        "    ! curl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "    ! bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "    ! rm Miniconda3-latest-Linux-x86_64.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "from google.colab import drive\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "%cd '/content/drive/MyDrive/sd/stable-diffusion-webui'\n",
        "\n",
        "!COMMANDLINE_ARGS=\"--update-check\"\n",
        "!COMMANDLINE_ARGS=\"--exit\" REQS_FILE=\"requirements.txt\" python launch.py\n",
        "my_pass = ''.join(random.choice(string.ascii_letters + string.digits) for i in range(32))\n",
        "os.environ[\"AUTO_USER\"] = my_pass\n",
        "print('==========================================')\n",
        "print(f'User is user, your password is: {my_pass}')\n",
        "print('==========================================')\n",
        "!COMMANDLINE_ARGS=\"--share --gradio-debug --gradio-auth user:$AUTO_USER\" REQS_FILE=\"requirements.txt\" python launch.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fegLSnbzSR6N",
        "outputId": "ce5e8d4a-619f-4ec7-d6da-98335fdfba2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "/content/drive/MyDrive/sd/stable-diffusion-webui\n",
            "Python 3.9.12 (main, Apr  5 2022, 06:56:58) \n",
            "[GCC 7.5.0]\n",
            "Commit hash: ccd73fc186603b626d996b888d628ebb6b1a38d8\n",
            "Installing torch and torchvision\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 255, in <module>\n",
            "    prepare_enviroment()\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 176, in prepare_enviroment\n",
            "    run_python(\"import torch; assert torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check'\")\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 58, in run_python\n",
            "    return run(f'\"{python}\" -c \"{code}\"', desc, errdesc)\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 34, in run\n",
            "    raise RuntimeError(message)\n",
            "RuntimeError: Error running command.\n",
            "Command: \"/usr/local/bin/python\" -c \"import torch; assert torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check'\"\n",
            "Error code: 1\n",
            "stdout: <empty>\n",
            "stderr: Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "AssertionError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check\n",
            "\n",
            "\n",
            "==========================================\n",
            "User is user, your password is: zxMCrVhHWljKxPFUJ3fmVWvFVQLQfmTg\n",
            "==========================================\n",
            "Python 3.9.12 (main, Apr  5 2022, 06:56:58) \n",
            "[GCC 7.5.0]\n",
            "Commit hash: ccd73fc186603b626d996b888d628ebb6b1a38d8\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 255, in <module>\n",
            "    prepare_enviroment()\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 176, in prepare_enviroment\n",
            "    run_python(\"import torch; assert torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check'\")\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 58, in run_python\n",
            "    return run(f'\"{python}\" -c \"{code}\"', desc, errdesc)\n",
            "  File \"/content/drive/MyDrive/sd/stable-diffusion-webui/launch.py\", line 34, in run\n",
            "    raise RuntimeError(message)\n",
            "RuntimeError: Error running command.\n",
            "Command: \"/usr/local/bin/python\" -c \"import torch; assert torch.cuda.is_available(), 'Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check'\"\n",
            "Error code: 1\n",
            "stdout: <empty>\n",
            "stderr: Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "AssertionError: Torch is not able to use GPU; add --skip-torch-cuda-test to COMMANDLINE_ARGS variable to disable this check\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}